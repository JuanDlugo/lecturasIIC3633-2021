En este paper se habla sobre como debemos evaluar a los algoritmos recomendadores para seleccionar el mejor candidato frente a cierto problema. Esto es muy importante ya que dependiendo la tarea que queramos cumplir un algortimo puede tener mejores o peores rendimientos. Inclusive los algoritmos deben ser medidos de forma distinta dependiendo el estado de la aplicación que estemos desarrollando. Por ejemplo, algunos son más eficientes en una configuración fuera de línea (offline), donde los enfoques de recomendación se comparan sin interacción del usuario. También está cuando la applicación revisa los estudios de usuarios, donde un pequeño grupo de sujetos experimenta con el sistema e informa sobre su experiencia. Y finalmente experimentos en línea a gran escala, donde las poblaciones de usuarios reales interactuan con el sistema.

-Offline Experiments:
 Probar algoritmos en escalas fueras de linea es muy fácil ya que no hay interacción con el usuario. Por otro lado, solo pueden responder preguntas relativamente sencillas. Es por esto que el objetivo de los experimentos fuera de línea es filtrar los enfoques inapropiados, dejando un conjunto relativamente pequeño de algoritmos candidatos para que los prueben los estudios de usuarios más costosos o los experimentos en línea.

 -User study:
 Un estudio de usuario se lleva a cabo reclutando un conjunto de sujetos de prueba y pidiéndoles que realicen varias tareas que requieren una interacción con el sistema de recomendaciones. Mientras los sujetos realizan las tareas, observamos y registramos su comportamiento, recolectando cualquier número de medidas cuantitativas, como qué parte de la tarea se completó, la precisión de los resultados de la tarea o el tiempo que se tomó para realizar la tarea. Un ejemplo típico de un experimento de este tipo es probar la influencia de un algoritmo de recomendación en el comportamiento de navegación de las noticias. Lo bueno de este tipo de experimentos es que nos permite realizar todo tipo de hipotesis y preguntas, además es el único entorno que nos permite recopilar datos cualitativos que a menudo son cruciales para interpretar los resultados cuantitativos. El problema que tienen es que son bastante caros (ya que debemos pagarle a varios usuarios para que usen el sistema) y por ende queremos extraer la mayor cantidad de información en el menor tiempo posible.

-Online Experiments:
Como lo que buscamos realmente es influenciar el comportamiento de nuestros usuarios online, realizar test online es lo más cercano a esto y por ende lo más representativo.
Es más confiable comparar algunos sistemas en línea, obteniendo una clasificación de alternativas, en lugar de números absolutos sobre métricas empleadas las cuales son más difíciles de interpretar.
Por esta razón, muchos sistemas del mundo real emplean un sistema de prueba en línea donde se pueden comparar múltiples algoritmos. Por lo general, estos sistemas redirigen un pequeño porcentaje de su tráfico a diferentes motores de recomendación alternativos y registran las interacciones de los usuarios con los diferentes sistemas. De todas manera existe un riesgo al correr esto experimentos online, ya que si el algoritmos que estamos probando es un desastre podemos darle al usuario recomendaciones malas y perder su atención.

Después el paper habla sobre distintas metricas para poder aprobar o rechazar una hipótesis (como el p-test por ejemplo) y también define varias características que poseen los sistemas recomendadores como la preferencia del usuario, Novedad, Precisión, Cobertura, Confianza, Diversidad, etc. 

Lo que me gusto de este paper es la cantidad de posturas y posiciones distintas que abarca y define. Nos explica como actuar para un montón de situaciones y que cosas tener en cuenta a la hora de enfrentarnos a un problema de ese tipo. La lectura es fluida y define todo de una manera muy legible por lo que se entiende como proceder en todos los casos. Además me gusto el punto donde se menciona que el score o Acurracy de un algortimo recomendador no lo es todo. Es un número y debemos analizar otras condiciones para ver efectivamente lo que representa este número. Esto no quiere decir que la métrica de la presición no tenga valor, por el contrario, es muy importante pero a veces nos cegamos con intentar de mejorarla más y más, sin entender otros apartados y fenómenos que también interfieren en el usuario.

Lo único que talvez no me gusto tanto del paper es que las características o propiedades de los sistemas recomendadores se trataron todas de manera muy apartada y lejanas. En ningún momento se relacionarón entre sí que es algo que yo creo que se debe de hacer puesto que normalmente conviven juntas en el sistema. 

